{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...welcome back!\n",
    "\n",
    "# TITANIC Part II\n",
    "\n",
    "##Machine Learning from Disaster: Introduction to Scikit-Learn\n",
    "\n",
    "This tutorial is based on the Kaggle Competition,\n",
    "\"Predicting Survival Aboard the Titanic\"    \n",
    "https://www.kaggle.com/c/titanic    \n",
    "\n",
    "As well as the following tutorials:    \n",
    "https://www.kaggle.com/mlchang/titanic/logistic-model-using-scikit-learn/run/91385    \n",
    "https://www.kaggle.com/c/titanic/details/getting-started-with-random-forests    \n",
    "https://github.com/savarin/pyconuk-introtutorial/tree/master/notebooks    \n",
    "\n",
    "See also:    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html    \n",
    "http://scikit-learn.org/stable/modules/svm.html    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.io.sql as pd_sql\n",
    "import sqlite3 as sql\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re-establish database connection\n",
    "con = sql.connect(\"titanic.db\") \n",
    "\n",
    "# extract everything from the 'training_data' table (or whatever you called it) into a dataframe\n",
    "train = pd_sql.read_sql('select * from training_data', con, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived  Pclass  \\\n",
       "index                                  \n",
       "0                1         0       3   \n",
       "1                2         1       1   \n",
       "2                3         1       3   \n",
       "3                4         1       1   \n",
       "4                5         0       3   \n",
       "\n",
       "                                                    Name     Sex  Age  SibSp  \\\n",
       "index                                                                          \n",
       "0                                Braund, Mr. Owen Harris    male   22      1   \n",
       "1      Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                                 Heikkinen, Miss. Laina  female   26      0   \n",
       "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                               Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "       Parch     Fare Cabin Embarked  \n",
       "index                                 \n",
       "0          0   7.2500  None        S  \n",
       "1          0  71.2833   C85        C  \n",
       "2          0   7.9250  None        S  \n",
       "3          0  53.1000  C123        S  \n",
       "4          0   8.0500  None        S  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Is it all still here?\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model: A Naive Approach\n",
    "\n",
    "Let's start by creating a model that predicts purely based on gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of passengers who survived is 0.383838383838.\n"
     ]
    }
   ],
   "source": [
    "# Set some variables\n",
    "number_passengers = train.shape[0] \n",
    "number_survived = len(train[train.Survived == 1])\n",
    "\n",
    "# What proportion of the passengers survived?\n",
    "proportion_survived = float(number_survived) / number_passengers\n",
    "print 'The proportion of passengers who survived is %s.' % proportion_survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of women who survived is 0.742038216561.\n",
      "The proportion of men who survived is 0.188908145581.\n"
     ]
    }
   ],
   "source": [
    "# How can we determine what proportion of the women and of the men who survived?\n",
    "# Let's start by segregating the men and women\n",
    "women = train[train.Sex == \"female\"]\n",
    "men = train[train.Sex != \"female\"]\n",
    "\n",
    "# Determine the proportion of women who survived\n",
    "proportion_women_survived = float(len(women[women.Survived == 1])) / len(women)\n",
    "print 'The proportion of women who survived is %s.' % proportion_women_survived\n",
    "\n",
    "# Determine the proportion of men who survived\n",
    "proportion_men_survived = float(len(men[men.Survived == 1])) / len(men)\n",
    "print 'The proportion of men who survived is %s.' % proportion_men_survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that women were MUCH more likely to survive, and we _could_ just say that our model is:\n",
    "    - if female => survived = 1\n",
    "    - if male => survived = 0\n",
    "    \n",
    "But that means our predictions are going to be wrong sometimes -- for about a quarter of the women and a fifth of the men. Let's use the Python library Scikit-learn to see if we can do a little better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-learn\n",
    "\n",
    "Scikit-Learn is a powerful machine learning library implemented in Python with numeric and scientific computing powerhouses Numpy, Scipy, and matplotlib for extremely fast analysis of small to medium-sized data sets. It is open source, commercially usable and contains many modern machine learning algorithms for classification, regression, clustering, feature extraction, and optimization. For this reason Scikit-Learn is often the first tool in a data scientist's toolkit for machine learning of incoming data sets.\n",
    "\n",
    "Scikit-learn will expect numeric values and no blanks, so first we need to do a bit more wrangling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'Sex' is stored as a text value. We should convert (or 'map') it into numeric binaries \n",
    "# so it will be ready for scikit-learn.\n",
    "train['Sex'] = train['Sex'].map({'male': 0,'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scikit-learn won't be tolerant of the missing values. In the last class, we dropped\n",
    "# the 'Ticket' column. Let's also drop the 'Cabin' and 'Embarked' columns\n",
    "train = train.drop(['Cabin'], axis=1)\n",
    "train = train.drop(['Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's also drop the 'Name' column for now (though I can think of some interesting \n",
    "# data that might be embedded in those salutations...)\n",
    "train = train.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've got a table of purely numeric data with no null values. We're ready to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression mathematically calculates the decision boundary between the possibilities. It looks for a straight line that represents a cutoff that most accurately represents the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test = pd.read_csv(\"../titanic/data/test.csv\") \n",
    "test[\"Age\"] = test[\"Age\"].fillna(df[\"Age\"].median())\n",
    "\n",
    "test.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "test.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "test = test.drop(['Cabin'], axis=1)\n",
    "test = test.drop(['Embarked'], axis=1)\n",
    "test = test.drop(['Name'], axis=1)\n",
    "test = test.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define our predictors\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\"]\n",
    "expected  = train[\"Survived\"]\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(train[predictors], expected)\n",
    "\n",
    "# Make predictions using the training set -- where we already know the correct answers\n",
    "predicted = alg.predict(train[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions based on the test data\n",
    "predictions = alg.predict(test[predictors])\n",
    "\n",
    "# Frame your submission for Kaggle\n",
    "kgl_submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that was easy!\n",
    "\n",
    "For Kaggle, the training samples are constructed by splitting our original dataset into more than one part. But what if certain chunks of our data have more variance than others? We want to ensure that our model performs just as well regardless of the particular way the data are divided up. So let's go back and do some cross-validation splits. \n",
    "\n",
    "### Cross-Validation\n",
    "\n",
    "More on cross-validation tools inside Scikit-learn here:    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\"]]\n",
    "y = train[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size = 0.2)\n",
    "clf = alg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74860335195530725"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But how do we know whether our model is good or not? Every estimator has a \n",
    "# score method that can judge the quality of the fit (or the prediction) on new data. \n",
    "# Bigger is better.   \n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.83      0.80       106\n",
      "          1       0.72      0.63      0.67        73\n",
      "\n",
      "avg / total       0.75      0.75      0.75       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also ask for a classification report. \n",
    "expected   = y_test\n",
    "predicted  = clf.predict(X_test)\n",
    "print classification_report(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how well did our Logistic Regression Model do?    \n",
    "\n",
    "Some models will work better than others! Let's try another one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is a 'meta estimator'. It will fit a number of decision trees (we'll have to \n",
    "tell it how many) on various sub-samples of the dataset. Then it will use averaging to improve \n",
    "the predictive accuracy and control over-fitting.\n",
    "\n",
    "Read more about Random Forests here:    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll select 50 trees and opt for 'out-of-bag' samples to estimate the generalization error.\n",
    "clf = RandomForestClassifier(n_estimators=50, oob_score=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next split up the data with the 'train test split' method in the Cross Validation module\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "# ...and then run the 'fit' method to build a forest of trees\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.83      0.84       107\n",
      "          1       0.75      0.76      0.76        72\n",
      "\n",
      "avg / total       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected   = y_test\n",
    "predicted  = clf.predict(X_test)\n",
    "print classification_report(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do with our Random Forest Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://github.com/rebeccabilbro/pyconuk-introtutorial/blob/master/notebooks/Section%202-2%20-%20SVM%20with%20Parameter%20Tuning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error    \n",
    "The mean squared error of an estimator measures the average difference between the expected and predicted results. An MSE of 0 -- meaning that the estimator predicts with perfect accuracy -- is the ideal, but is highly unlikely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.240\n"
     ]
    }
   ],
   "source": [
    "print \"Mean Squared Error: %0.3f\" % mse(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not terrible.    \n",
    "\n",
    "### Coefficient of Deterimination    \n",
    "The coefficient of determination (R squared or R^2) indicates how well data fit a statistical model â€“ sometimes simply a line or a curve. An R^2 of 1 indicates that the regression line perfectly fits the data, while an R^2 of 0 indicates that the line does not fit the data at all. This latter can be because the data is non-linear, or because it is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of Determination: -0.004\n"
     ]
    }
   ],
   "source": [
    "print \"Coefficient of Determination: %0.3f\" % r2_score(expected, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
